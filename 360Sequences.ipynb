{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rrH-nJyCpvq",
        "outputId": "b1769c42-55c6-4c7b-c656-ce391fe9b978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import string\n",
        "import gc\n",
        "import re\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk.lm import MLE\n",
        "import pickle\n",
        "from scipy.stats import skew\n",
        "import cv2\n",
        "import math\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from string import printable\n",
        "from re import X\n",
        "from IPython.core import formatters\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from io import open\n",
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[[1,1],[2,2]], [[3,3],[4,4]]])\n",
        "print(np.array([[[1,1],[2,2]], [[3,3],[4,4]]]).shape)\n",
        "a_reshaped = a.reshape(a.shape[0], -1)\n",
        "print(a)\n",
        "print(a_reshaped)\n",
        "np.savetxt('test1.txt', a_reshaped)\n",
        "b = np.loadtxt('test1.txt')\n",
        "print('')\n",
        "print(b)\n",
        "b = b.reshape(len(b), len(a[0]), a.shape[2])\n",
        "print(b)\n",
        "a == b\n",
        "# array([ True,  True,  True,  True], dtype=bool)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ubPq9QBH3fW",
        "outputId": "5d101cc5-fac5-4881-8dc8-d9a893f36e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 2, 2)\n",
            "[[[1 1]\n",
            "  [2 2]]\n",
            "\n",
            " [[3 3]\n",
            "  [4 4]]]\n",
            "[[1 1 2 2]\n",
            " [3 3 4 4]]\n",
            "\n",
            "[[1. 1. 2. 2.]\n",
            " [3. 3. 4. 4.]]\n",
            "[[[1. 1.]\n",
            "  [2. 2.]]\n",
            "\n",
            " [[3. 3.]\n",
            "  [4. 4.]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ True,  True],\n",
              "        [ True,  True]],\n",
              "\n",
              "       [[ True,  True],\n",
              "        [ True,  True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?']+\", r\" \", s)\n",
        "    return s\n",
        "\n",
        "MAX_LENGTH =  300"
      ],
      "metadata": {
        "id": "yovP0siGRKLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "videos = ['/content/rachel1.mp4', '/content/1-Ben-Introduction-SD.mov']\n",
        "xml = ['/content/xml_extract_Rachel_2012-01-27_sc51_9.xml', 'xml_extract_1-Ben-Introduction_17.xml']\n",
        "\n",
        "sequences =  []\n",
        "translatedSequences =  []\n",
        "AllSigns = []\n",
        "AllFrames = []\n",
        "AllFramesUncompressed = []\n",
        "Labels = []\n",
        "\n",
        "for video, xml in zip(videos, xml):\n",
        "  capture = cv2.VideoCapture(video)\n",
        "  count = 0\n",
        "  frames = []\n",
        "  frameNr = 0\n",
        "  \n",
        "  while (True):\n",
        "      success, frame = capture.read()\n",
        "      if success:\n",
        "          frame = cv2.resize(frame, (320,240), interpolation = cv2.INTER_AREA)\n",
        "          frames.append(frame)\n",
        "      else:\n",
        "          break\n",
        "      count = count+1\n",
        "  capture.release()\n",
        "\n",
        "  print(len(frames))\n",
        "\n",
        "  tree = ET.parse(xml)\n",
        "  \n",
        "  # getting the parent tag of\n",
        "  # the xml document\n",
        "  root = tree.getroot()\n",
        "  \n",
        "  # printing the root (parent) tag\n",
        "  # of the xml document, along with\n",
        "  # its memory location\n",
        "  print(root)\n",
        "  \n",
        "  # printing the attributes of the\n",
        "  # first tag from the parent\n",
        "  print(root[0].attrib)\n",
        "  \n",
        "  # printing the text contained within\n",
        "  # first subtag of the 5th tag from\n",
        "  # the parent\n",
        "  print(root[0][0][3][0][0][0][2])\n",
        "\n",
        "  utterances= tree.findall('.//UTTERANCE')\n",
        "  signs = utterances[1][3].findall('.//SIGN')\n",
        "  UtteranceSigns = utterances[1][3].findall('.//SIGN')\n",
        "\n",
        "  for sign  in tree.findall('.//SIGN'):\n",
        "    # check if exists in unique_list or not\n",
        "    if sign[0].text not in AllSigns:\n",
        "      AllSigns.append(sign[0].text)\n",
        "\n",
        "  label_map1 = {num:label for num, label in enumerate(AllSigns)}\n",
        "  label_map2 = {label:num for num, label in enumerate(AllSigns)}\n",
        "\n",
        "  \n",
        "  for utterance in utterances:\n",
        "      UtteranceSigns = utterance[3].findall('.//SIGN')\n",
        "      UtteranceSignsSorted = sorted(UtteranceSigns, key=lambda x: x[13].get('START_FRAME'))\n",
        "      utteranceFrameSigns = []\n",
        "      signIDs = []\n",
        "      FrameSequence = []\n",
        "      FrameSequenceUncompressed = []\n",
        "      SignSequence = \"\"\n",
        "      a=0\n",
        "      for sign in UtteranceSignsSorted:\n",
        "        if sign.get('ID') not in signIDs:\n",
        "          signIDs.append(sign.get('ID'))\n",
        "          for frame_num in range(int(int(sign[13].get('START_FRAME'))/1000),int(int(sign[13].get('END_FRAME'))/1000)):\n",
        "            if (frame_num - (int(int(sign[13].get('START_FRAME'))/1000)) ) % 3 == 0:\n",
        "              FrameSequence.append(frames[frame_num-1].flatten())\n",
        "              FrameSequenceUncompressed.append(frames[frame_num-1])\n",
        "              utteranceFrameSigns.append(label_map2[sign[0].text])\n",
        "      Labels.append(utteranceFrameSigns)\n",
        "      translatedSequences.append(normalizeString(utterance[0].text))\n",
        "      sequences.append(normalizeString(SignSequence))\n",
        "      AllFrames.append(FrameSequence)\n",
        "      AllFramesUncompressed.append(FrameSequenceUncompressed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi8JLLsCEKZW",
        "outputId": "9095a089-a990-451f-b4ee-01cca0cd40f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6996\n",
            "<Element 'SIGNSTREAM_DAI' at 0x7f4e17caa650>\n",
            "{}\n",
            "<Element 'UTTERANCES' at 0x7f4e17caafb0>\n",
            "4409\n",
            "<Element 'SIGNSTREAM_DAI' at 0x7f4e17cc4890>\n",
            "{}\n",
            "<Element 'UTTERANCES' at 0x7f4e17cd50b0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skinMask360Sequences = []\n",
        "for utterance in AllFramesUncompressed:\n",
        "  skinMask360Utterance = [] \n",
        "  for frame in utterance:\n",
        "\n",
        "    img = frame.copy()\n",
        "    img_bw = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # to be considered 'skin'\n",
        "    hsvim = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    lower = np.array([0, 48, 80], dtype=\"uint8\")\n",
        "    upper = np.array([30, 255, 255], dtype=\"uint8\")\n",
        "    skinMask= cv2.inRange(hsvim, lower, upper)\n",
        "\n",
        "    # blur the mask to help remove noise\n",
        "    skinMask = cv2.blur(skinMask, (15, 15))\n",
        "\n",
        "    # get threshold image\n",
        "    ret, thresh = cv2.threshold(skinMask, 100, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "    distancesPerBlob = []\n",
        "\n",
        "    # find contours in the binary image\n",
        "    # Convert source image to unsigned 8 bit integer Numpy array\n",
        "    # help(cv2.cvtColor)\n",
        "    contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
        "    cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
        "\n",
        "    count= 0\n",
        "\n",
        "\n",
        "    for c in cntsSorted:\n",
        "\n",
        "      if(count == 3):\n",
        "        break;\n",
        "\n",
        "      count = count+1;\n",
        "\n",
        "      # Step #3\n",
        "      out = img.copy()\n",
        "\n",
        "      # Step #4\n",
        "      ref = np.zeros_like(img_bw)\n",
        "      cv2.drawContours(ref, c, -1, 255, 5)\n",
        "\n",
        "\n",
        "      width = img.shape[1]\n",
        "      height = img.shape[0]\n",
        "\n",
        "      # Define total number of angles we want\n",
        "      N = 360\n",
        "\n",
        "      # Step #5\n",
        "      M = cv2.moments(c)\n",
        "\n",
        "      if(M['m00'] == 0):\n",
        "        count = count-1;\n",
        "        continue\n",
        "\n",
        "      centroid_x = int(M['m10']/M['m00'])\n",
        "      centroid_y = int(M['m01']/M['m00'])\n",
        "\n",
        "      # Step #6\n",
        "      for i in range(N):\n",
        "        # Step #6a\n",
        "        tmp = np.zeros_like(img_bw)\n",
        "\n",
        "        # Step #6b\n",
        "        theta = i*(360/N)\n",
        "        theta *= np.pi/180.0\n",
        "\n",
        "        # Step #6c\n",
        "        cv2.line(tmp, (centroid_x, centroid_y),\n",
        "        (int(centroid_x+np.cos(theta)*width),\n",
        "        int(centroid_y-np.sin(theta)*height)), 255, 5)\n",
        "\n",
        "        # Step #6d\n",
        "        (row,col) = np.nonzero(np.logical_and(tmp, ref))\n",
        "\n",
        "        # Step #6e\n",
        "        try:\n",
        "          cv2.line(out, (centroid_x, centroid_y), (col[0],row[0]), 0, 1)\n",
        "          distancesPerBlob.append(math.hypot(col[0] - centroid_x, row[0] - centroid_y))\n",
        "        except:\n",
        "          distancesPerBlob.append(0)\n",
        "      \n",
        "    while len(distancesPerBlob) < 1080:\n",
        "        distancesPerBlob.append(0)\n",
        "    skinMask360Utterance.append(distancesPerBlob)\n",
        "  skinMask360Sequences.append(skinMask360Utterance)"
      ],
      "metadata": {
        "id": "Xc2cTR8eEKkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_inputs2 = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    skinMask360Sequences, padding=\"post\", value=-1\n",
        ")"
      ],
      "metadata": {
        "id": "xkyVtX4DPtvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_inputs2.shape"
      ],
      "metadata": {
        "id": "t_p9yXUbiLXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f693dd24-1385-476b-9090-2de48a68f292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 93, 1080)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a2 = np.array(padded_inputs2)\n",
        "print(np.array(padded_inputs2).shape)\n",
        "a2_reshaped = a2.reshape(a2.shape[0], -1)\n",
        "print(a2)\n",
        "print(a2_reshaped)\n",
        "np.savetxt('360Arrays.txt', a2_reshaped)\n",
        "b2 = np.loadtxt('360Arrays.txt')\n",
        "print('')\n",
        "print(b2.shape)\n",
        "b2 = b2.reshape(len(b2), len(a2[0]), a2.shape[2])\n",
        "print(b2.shape)\n",
        "a2 == b2\n",
        "# array([ True,  True,  True,  True], dtype=bool)"
      ],
      "metadata": {
        "id": "6QgqGaIPQamb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "593f6577-1787-40b6-c8c1-2ee181760bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56, 93, 1080)\n",
            "[[[10 10 10 ...  0  0  0]\n",
            "  [11 11 11 ...  0  0  0]\n",
            "  [10 10 10 ...  0  0  0]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[22 22 23 ...  0  0  0]\n",
            "  [24 24 24 ...  0  0  0]\n",
            "  [22 22 22 ...  0  0  0]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[17 17 18 ... 14 14 14]\n",
            "  [16 16 18 ...  8  8  8]\n",
            "  [17 17 18 ... 15 15 15]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[20 20 21 ...  0  0  0]\n",
            "  [24 24 24 ...  0  0  0]\n",
            "  [20 20 21 ...  0  0  0]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[21 21 21 ... 16 16 16]\n",
            "  [21 21 21 ...  5  5  5]\n",
            "  [18 18 19 ...  0  0  0]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]\n",
            "\n",
            " [[18 18 18 ...  0  0  0]\n",
            "  [22 22 23 ...  0  0  0]\n",
            "  [10 10 10 ...  0  0  0]\n",
            "  ...\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]\n",
            "  [-1 -1 -1 ... -1 -1 -1]]]\n",
            "[[10 10 10 ... -1 -1 -1]\n",
            " [22 22 23 ... -1 -1 -1]\n",
            " [17 17 18 ... -1 -1 -1]\n",
            " ...\n",
            " [20 20 21 ... -1 -1 -1]\n",
            " [21 21 21 ... -1 -1 -1]\n",
            " [18 18 18 ... -1 -1 -1]]\n",
            "\n",
            "(56, 100440)\n",
            "(56, 93, 1080)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]],\n",
              "\n",
              "       [[ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        ...,\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True],\n",
              "        [ True,  True,  True, ...,  True,  True,  True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b2.shape"
      ],
      "metadata": {
        "id": "N9qTOXdNi5U9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43b7948a-9afc-4144-c329-dec43591049c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56, 93, 1080)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}